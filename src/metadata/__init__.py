"""
Metadata Module - Next-Generation Code Understanding

This module provides LLM-powered code analysis and metadata generation using:
1. GPT-4-mini for efficient metadata generation
2. Gemini 1.5 Pro's 2M token context window for retrieval
3. DeepSeek R1 for deep reasoning
"""

from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime

@dataclass
class MetadataRequest:
    """Configuration for metadata generation."""
    include_relationships: bool = True
    include_complexity: bool = True
    include_patterns: bool = True
    include_performance: bool = True
    max_context_window: int = 2_000_000  # 2M tokens for Gemini

@dataclass
class CodeMetadata:
    """Rich metadata generated by LLM analysis."""
    # Core metadata
    language: str
    file_path: str
    chunk_type: str
    start_line: int
    end_line: int
    
    # LLM-generated insights
    imports: List[str] = field(default_factory=list)
    functions: List[Dict[str, Any]] = field(default_factory=list)
    classes: List[Dict[str, Any]] = field(default_factory=list)
    types: Dict[str, str] = field(default_factory=dict)
    dependencies: Dict[str, List[str]] = field(default_factory=dict)
    patterns: List[str] = field(default_factory=list)
    security_issues: List[str] = field(default_factory=list)
    performance_notes: List[str] = field(default_factory=list)
    
    # Timestamps
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)

# Re-export key components
from .types import AnalysisResult, CodeContext

__all__ = [
    'MetadataRequest',
    'CodeMetadata',
    'AnalysisResult',
    'CodeContext'
]